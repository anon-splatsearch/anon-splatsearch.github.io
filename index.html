<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="SplatSearch">
  <meta name="keywords" content="Mobile Robot Navigation, 3D Gaussian Splatting, Diffusion Models, Instance Image Goal Navigation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" referrerpolicy="no-referrer" /> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


  <meta property="og:site_name" content="SplatSearch" />
  <meta property="og:type" content="website" />
  <meta property="og:title" content="SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models" />
  <meta property="og:description" content="Anonymous Research Submission" />
  <meta property="og:url" content="https://anonymous-splatsearch.github.io/" />
  <meta property="article:publisher" content="#" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models" />
  <meta name="twitter:description" content="Anonymous Research Submission" />
  <meta name="twitter:url" content="https://anonymous-splatsearch.github.io/" />
  <meta name="twitter:site" content="@anonymous" />
</head>


<body>

<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-four-fifths has-text-centered">
          <h1 class="title is-1 publication-title">SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models</h1>
          <div class="is-size-3 publication-authors">
            Anonymous Authors
          </div>
          
          <!-- Links removed for anonymous submission -->
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="background-color: #f8f9fa; padding: 40px 0;">
  <div class="container">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The Instance Image Goal Navigation (IIN) problem requires mobile robots deployed in unknown environments to search for specific objects or people of interest using only a single reference goal image of the target. This problem can be especially challenging when: 1) the reference image is captured from an arbitrary viewpoint, and 2) the robot must operate with sparse-view scene reconstructions. In this paper, we address the IIN problem, by introducing SplatSearch, a novel architecture that leverages sparse-view 3D Gaussian Splatting (3DGS) reconstructions. SplatSearch renders multiple viewpoints around candidate objects using a sparse online 3DGS map, and uses a multi-view diffusion model to complete missing regions of the rendered images, enabling robust feature matching against the goal image. A novel frontier exploration policy is introduced which uses visual context from the synthesized viewpoints with semantic context from the goal image to evaluate frontier locations, allowing the robot to prioritize frontiers that are semantically and visually relevant to the goal image. Extensive experiments in photorealistic home and real-world environments validate the higher performance of SplatSearch against current state-of-the-art methods in terms of Success Rate and Success Path Length. An ablation study confirms the design choices of SplatSearch.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-full-width is-centered has-text-centered">
        <h2 class="title is-2" style="text-align: center;">Experiment Video</h2>
        <video controls controlsList="nodownload" autoplay loop muted playsinline src="./resources/splatsearch_video.mp4" poster="./resources/loading-icon.gif" style="width: 100%; max-width: 1100px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);" oncontextmenu="return false;"></video>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <!-- Architecture Title and Description -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">SplatSearch Architecture</h2>
        <div class="content has-text-justified">
          <p>
            The SplatSearch architecture, consisting of: 1) Map Generation Module (MGM) which generates a 3DGS map for photorealistic mapping and occupancy map for frontier exploration, 2) Semantic Object Identification Module (SOIM) detects if a current RGB image contains an object with the same class as the goal image, 3) Novel Viewpoint Synthesis Module (NVSM) generates multiple viewpoints around the object, 4) View-Consistent Image Completion Network (VCICN) inpaints the sparse viewpoint images from NVSM, 5) Feature Extraction Module (FEM) which uses the inpainted images to match features with the goal image, and 6) Exploration Planner (EP) which selects and generates feasible paths towards new frontiers.
          </p>
        </div>
      </div>
    </div>
    <!-- Architecture Image -->
    <div class="columns is-centered">
      <div class="column is-full-width is-centered has-text-centered">
        <img src="./static/images/architecture.png" alt="SplatSearch Architecture Diagram" style="width: 100%; max-width: 1100px; margin: 20px auto; display: block;">
      </div>
    </div>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>Page template from <a href="https://robot-parkour.github.io/"><span class="dnerf">Robot Parkour Learning</span></a></p>
    </div>
  </div>
</footer>

</body>
</html>